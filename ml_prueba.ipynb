{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_parquet(r'E:\\Data Science\\PF\\ML_streamlit\\Datos\\ML_1.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars_x</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>categories</th>\n",
       "      <th>fecha</th>\n",
       "      <th>cantidad</th>\n",
       "      <th>analisis_sentimiento</th>\n",
       "      <th>stars_y</th>\n",
       "      <th>useful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>---kPU91CF4Lq2-WlRu9Lw</td>\n",
       "      <td>Frankie's Raw Bar</td>\n",
       "      <td>4903 State Rd 54</td>\n",
       "      <td>Elfers</td>\n",
       "      <td>FL</td>\n",
       "      <td>34652</td>\n",
       "      <td>28.217288</td>\n",
       "      <td>-82.733344</td>\n",
       "      <td>4.5</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>Latin American</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>---kPU91CF4Lq2-WlRu9Lw</td>\n",
       "      <td>Frankie's Raw Bar</td>\n",
       "      <td>4903 State Rd 54</td>\n",
       "      <td>Elfers</td>\n",
       "      <td>FL</td>\n",
       "      <td>34652</td>\n",
       "      <td>28.217288</td>\n",
       "      <td>-82.733344</td>\n",
       "      <td>4.5</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>Fast Food</td>\n",
       "      <td>2020-03-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>---kPU91CF4Lq2-WlRu9Lw</td>\n",
       "      <td>Frankie's Raw Bar</td>\n",
       "      <td>4903 State Rd 54</td>\n",
       "      <td>Elfers</td>\n",
       "      <td>FL</td>\n",
       "      <td>34652</td>\n",
       "      <td>28.217288</td>\n",
       "      <td>-82.733344</td>\n",
       "      <td>4.5</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>Latin American</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>---kPU91CF4Lq2-WlRu9Lw</td>\n",
       "      <td>Frankie's Raw Bar</td>\n",
       "      <td>4903 State Rd 54</td>\n",
       "      <td>Elfers</td>\n",
       "      <td>FL</td>\n",
       "      <td>34652</td>\n",
       "      <td>28.217288</td>\n",
       "      <td>-82.733344</td>\n",
       "      <td>4.5</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>Fast Food</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>---kPU91CF4Lq2-WlRu9Lw</td>\n",
       "      <td>Frankie's Raw Bar</td>\n",
       "      <td>4903 State Rd 54</td>\n",
       "      <td>Elfers</td>\n",
       "      <td>FL</td>\n",
       "      <td>34652</td>\n",
       "      <td>28.217288</td>\n",
       "      <td>-82.733344</td>\n",
       "      <td>4.5</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>Latin American</td>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id               name           address    city state  \\\n",
       "0  ---kPU91CF4Lq2-WlRu9Lw  Frankie's Raw Bar  4903 State Rd 54  Elfers    FL   \n",
       "1  ---kPU91CF4Lq2-WlRu9Lw  Frankie's Raw Bar  4903 State Rd 54  Elfers    FL   \n",
       "2  ---kPU91CF4Lq2-WlRu9Lw  Frankie's Raw Bar  4903 State Rd 54  Elfers    FL   \n",
       "3  ---kPU91CF4Lq2-WlRu9Lw  Frankie's Raw Bar  4903 State Rd 54  Elfers    FL   \n",
       "4  ---kPU91CF4Lq2-WlRu9Lw  Frankie's Raw Bar  4903 State Rd 54  Elfers    FL   \n",
       "\n",
       "  postal_code   latitude  longitude  stars_x  review_count  is_open  \\\n",
       "0       34652  28.217288 -82.733344      4.5            24        1   \n",
       "1       34652  28.217288 -82.733344      4.5            24        1   \n",
       "2       34652  28.217288 -82.733344      4.5            24        1   \n",
       "3       34652  28.217288 -82.733344      4.5            24        1   \n",
       "4       34652  28.217288 -82.733344      4.5            24        1   \n",
       "\n",
       "       categories      fecha  cantidad  analisis_sentimiento  stars_y  useful  \n",
       "0  Latin American 2020-03-01         1                   2.0      5.0     2.0  \n",
       "1       Fast Food 2020-03-01         1                   2.0      5.0     2.0  \n",
       "2  Latin American 2020-06-01         1                   1.5      3.5     2.0  \n",
       "3       Fast Food 2020-06-01         1                   1.5      3.5     2.0  \n",
       "4  Latin American 2020-10-01         1                   2.0      5.0     3.0  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5798"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['name'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "categories\n",
       "American          137181\n",
       "Mexican            26023\n",
       "Fast Food          20722\n",
       "East Asian         13974\n",
       "Latin American      6487\n",
       "African             1807\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['categories'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "latitude\n",
       "27.812603    308\n",
       "27.921942    288\n",
       "27.976757    225\n",
       "34.418889    216\n",
       "27.777410    210\n",
       "            ... \n",
       "39.945703      1\n",
       "39.956166      1\n",
       "34.439762      1\n",
       "39.959695      1\n",
       "28.064665      1\n",
       "Name: count, Length: 7985, dtype: int64"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['latitude'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos los dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies=pd.get_dummies(df['categories'], dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies = pd.concat([df_dummies, df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dummies.drop(['categories','business_id','name','address','postal_code','is_open','state','fecha'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>African</th>\n",
       "      <th>American</th>\n",
       "      <th>East Asian</th>\n",
       "      <th>Fast Food</th>\n",
       "      <th>Latin American</th>\n",
       "      <th>Mexican</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars_x</th>\n",
       "      <th>review_count</th>\n",
       "      <th>cantidad</th>\n",
       "      <th>analisis_sentimiento</th>\n",
       "      <th>stars_y</th>\n",
       "      <th>useful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Elfers</td>\n",
       "      <td>28.217288</td>\n",
       "      <td>-82.733344</td>\n",
       "      <td>4.5</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Elfers</td>\n",
       "      <td>28.217288</td>\n",
       "      <td>-82.733344</td>\n",
       "      <td>4.5</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Elfers</td>\n",
       "      <td>28.217288</td>\n",
       "      <td>-82.733344</td>\n",
       "      <td>4.5</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Elfers</td>\n",
       "      <td>28.217288</td>\n",
       "      <td>-82.733344</td>\n",
       "      <td>4.5</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Elfers</td>\n",
       "      <td>28.217288</td>\n",
       "      <td>-82.733344</td>\n",
       "      <td>4.5</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   African   American  East Asian  Fast Food  Latin American  Mexican    city  \\\n",
       "0         0         0           0          0               1        0  Elfers   \n",
       "1         0         0           0          1               0        0  Elfers   \n",
       "2         0         0           0          0               1        0  Elfers   \n",
       "3         0         0           0          1               0        0  Elfers   \n",
       "4         0         0           0          0               1        0  Elfers   \n",
       "\n",
       "    latitude  longitude  stars_x  review_count  cantidad  \\\n",
       "0  28.217288 -82.733344      4.5            24         1   \n",
       "1  28.217288 -82.733344      4.5            24         1   \n",
       "2  28.217288 -82.733344      4.5            24         1   \n",
       "3  28.217288 -82.733344      4.5            24         1   \n",
       "4  28.217288 -82.733344      4.5            24         1   \n",
       "\n",
       "   analisis_sentimiento  stars_y  useful  \n",
       "0                   2.0      5.0     2.0  \n",
       "1                   2.0      5.0     2.0  \n",
       "2                   1.5      3.5     2.0  \n",
       "3                   1.5      3.5     2.0  \n",
       "4                   2.0      5.0     3.0  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 206194 entries, 0 to 206193\n",
      "Data columns (total 15 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   African               206194 non-null  int32  \n",
      " 1   American              206194 non-null  int32  \n",
      " 2   East Asian            206194 non-null  int32  \n",
      " 3   Fast Food             206194 non-null  int32  \n",
      " 4   Latin American        206194 non-null  int32  \n",
      " 5   Mexican               206194 non-null  int32  \n",
      " 6   city                  206194 non-null  object \n",
      " 7   latitude              206194 non-null  float64\n",
      " 8   longitude             206194 non-null  float64\n",
      " 9   stars_x               206194 non-null  float32\n",
      " 10  review_count          206194 non-null  int64  \n",
      " 11  cantidad              206194 non-null  int64  \n",
      " 12  analisis_sentimiento  206194 non-null  float64\n",
      " 13  stars_y               206194 non-null  float64\n",
      " 14  useful                206194 non-null  float64\n",
      "dtypes: float32(1), float64(5), int32(6), int64(2), object(1)\n",
      "memory usage: 18.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_dummies.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=df_dummies['city']\n",
    "X=df_dummies.drop(['city'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Crear instancia de LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Ajustar y transformar 'y' para convertir las etiquetas de ciudad a valores numéricos\n",
    "y_train_encoded = encoder.fit_transform(y_train)\n",
    "y_test_encoded = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Crear el modelo de clasificación\n",
    "modelo_rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Entrenar el modelo con datos codificados\n",
    "modelo_rf.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Realizar predicciones\n",
    "predicciones = modelo_rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decodificar las predicciones para obtener los nombres de las ciudades\n",
    "predicciones_ciudades = encoder.inverse_transform(predicciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99        76\n",
      "           1       0.99      1.00      0.99        87\n",
      "           2       1.00      1.00      1.00       124\n",
      "           3       0.99      1.00      0.99       285\n",
      "           4       0.98      1.00      0.99        91\n",
      "           5       1.00      1.00      1.00        11\n",
      "           6       1.00      1.00      1.00       433\n",
      "           8       1.00      1.00      1.00       194\n",
      "           9       1.00      0.66      0.79        35\n",
      "          10       0.94      0.83      0.88        18\n",
      "          11       1.00      0.98      0.99        44\n",
      "          12       1.00      1.00      1.00        15\n",
      "          13       1.00      1.00      1.00       105\n",
      "          14       0.96      0.98      0.97       153\n",
      "          15       1.00      0.99      0.99        69\n",
      "          16       1.00      1.00      1.00       157\n",
      "          17       1.00      1.00      1.00       102\n",
      "          18       1.00      0.94      0.97        17\n",
      "          19       0.82      1.00      0.90         9\n",
      "          20       1.00      1.00      1.00       759\n",
      "          21       0.95      0.97      0.96        64\n",
      "          22       1.00      0.97      0.98        60\n",
      "          23       0.95      0.95      0.95        21\n",
      "          24       0.81      0.72      0.76        18\n",
      "          25       0.98      1.00      0.99       125\n",
      "          26       1.00      1.00      1.00        58\n",
      "          27       1.00      1.00      1.00       145\n",
      "          28       1.00      1.00      1.00         7\n",
      "          29       1.00      1.00      1.00       240\n",
      "          30       0.98      1.00      0.99       315\n",
      "          31       1.00      0.95      0.98       167\n",
      "          32       1.00      1.00      1.00      2801\n",
      "          33       1.00      0.97      0.98        31\n",
      "          34       1.00      1.00      1.00        56\n",
      "          35       1.00      0.77      0.87        13\n",
      "          36       1.00      0.99      0.99       312\n",
      "          37       1.00      0.33      0.50         3\n",
      "          38       0.88      1.00      0.94        15\n",
      "          39       1.00      0.98      0.99       102\n",
      "          40       1.00      1.00      1.00        31\n",
      "          41       0.99      1.00      1.00       223\n",
      "          42       1.00      1.00      1.00      1030\n",
      "          43       0.92      0.92      0.92        13\n",
      "          44       0.95      1.00      0.98        42\n",
      "          45       1.00      1.00      1.00        12\n",
      "          46       1.00      1.00      1.00       193\n",
      "          47       1.00      1.00      1.00        14\n",
      "          48       0.99      1.00      0.99       158\n",
      "          49       0.97      1.00      0.98        31\n",
      "          50       1.00      1.00      1.00        31\n",
      "          51       0.00      0.00      0.00         1\n",
      "          52       0.00      0.00      0.00         0\n",
      "          53       1.00      0.98      0.99        44\n",
      "          54       0.95      1.00      0.97        18\n",
      "          55       1.00      0.97      0.99        68\n",
      "          56       1.00      1.00      1.00       259\n",
      "          57       1.00      1.00      1.00        16\n",
      "          58       0.90      0.78      0.84        36\n",
      "          59       1.00      1.00      1.00         5\n",
      "          60       1.00      1.00      1.00       423\n",
      "          61       1.00      1.00      1.00        57\n",
      "          62       0.69      0.75      0.72        12\n",
      "          63       1.00      0.93      0.96        28\n",
      "          64       0.99      1.00      1.00       118\n",
      "          65       0.94      1.00      0.97        17\n",
      "          66       0.97      1.00      0.98        94\n",
      "          67       1.00      0.95      0.97        37\n",
      "          68       1.00      0.91      0.95        11\n",
      "          69       1.00      1.00      1.00      1149\n",
      "          70       0.88      1.00      0.93        56\n",
      "          71       1.00      0.98      0.99        52\n",
      "          72       0.00      0.00      0.00         1\n",
      "          73       1.00      1.00      1.00         3\n",
      "          74       0.99      1.00      1.00       193\n",
      "          75       0.94      1.00      0.97       129\n",
      "          76       0.99      1.00      0.99       165\n",
      "          77       1.00      1.00      1.00       183\n",
      "          78       1.00      1.00      1.00        39\n",
      "          79       1.00      0.97      0.98        29\n",
      "          80       1.00      0.86      0.92         7\n",
      "          81       1.00      0.59      0.74        17\n",
      "          82       1.00      1.00      1.00        20\n",
      "          83       1.00      1.00      1.00       185\n",
      "          84       1.00      1.00      1.00        27\n",
      "          85       0.90      0.82      0.86        11\n",
      "          86       0.91      0.83      0.87        12\n",
      "          87       1.00      1.00      1.00        59\n",
      "          88       1.00      0.99      1.00       292\n",
      "          89       1.00      0.83      0.91         6\n",
      "          90       0.99      1.00      0.99       351\n",
      "          91       1.00      1.00      1.00       160\n",
      "          92       1.00      0.67      0.80         3\n",
      "          93       1.00      1.00      1.00        41\n",
      "          94       0.89      0.96      0.93        26\n",
      "          95       1.00      0.98      0.99        61\n",
      "          96       0.94      0.86      0.90        36\n",
      "          97       1.00      0.75      0.86        16\n",
      "          98       1.00      1.00      1.00        37\n",
      "          99       1.00      0.84      0.91        19\n",
      "         100       1.00      1.00      1.00       287\n",
      "         101       0.95      0.98      0.96        55\n",
      "         102       1.00      0.99      1.00       118\n",
      "         103       1.00      0.99      0.99        67\n",
      "         104       1.00      1.00      1.00       482\n",
      "         105       1.00      0.91      0.95        44\n",
      "         106       0.93      0.98      0.95       149\n",
      "         107       1.00      1.00      1.00       117\n",
      "         108       0.95      0.95      0.95        19\n",
      "         109       0.99      1.00      1.00       268\n",
      "         110       0.99      1.00      1.00       168\n",
      "         111       1.00      1.00      1.00        17\n",
      "         112       1.00      0.97      0.99        73\n",
      "         113       1.00      1.00      1.00       540\n",
      "         114       0.95      0.95      0.95        40\n",
      "         115       1.00      0.98      0.99        51\n",
      "         116       1.00      1.00      1.00        62\n",
      "         117       0.99      0.99      0.99       171\n",
      "         118       1.00      1.00      1.00        20\n",
      "         119       1.00      1.00      1.00        55\n",
      "         120       0.99      0.99      0.99       120\n",
      "         121       0.93      1.00      0.96        13\n",
      "         122       0.99      1.00      1.00       222\n",
      "         123       1.00      1.00      1.00       421\n",
      "         124       0.83      0.56      0.67         9\n",
      "         125       0.96      0.98      0.97        44\n",
      "         126       1.00      0.98      0.99        41\n",
      "         127       0.00      0.00      0.00         0\n",
      "         128       1.00      1.00      1.00       107\n",
      "         129       0.97      0.97      0.97        29\n",
      "         130       0.99      0.99      0.99       197\n",
      "         131       0.98      0.99      0.99       190\n",
      "         132       1.00      0.99      1.00       111\n",
      "         133       0.98      1.00      0.99        40\n",
      "         134       1.00      1.00      1.00        10\n",
      "         135       0.98      0.98      0.98       129\n",
      "         136       1.00      1.00      1.00        12\n",
      "         137       0.98      1.00      0.99       235\n",
      "         138       0.99      1.00      1.00       353\n",
      "         139       1.00      1.00      1.00       166\n",
      "         140       0.98      1.00      0.99       233\n",
      "         141       0.96      1.00      0.98        24\n",
      "         142       0.90      1.00      0.95        27\n",
      "         143       1.00      0.90      0.95        39\n",
      "         144       1.00      1.00      1.00         1\n",
      "         145       0.99      1.00      1.00       273\n",
      "         146       1.00      0.96      0.98        91\n",
      "         147       1.00      0.81      0.89        21\n",
      "         148       0.99      1.00      0.99       164\n",
      "         149       1.00      1.00      1.00         9\n",
      "         150       0.99      1.00      1.00       207\n",
      "         151       0.95      0.98      0.97        57\n",
      "         152       1.00      1.00      1.00        13\n",
      "         153       1.00      1.00      1.00        57\n",
      "         154       0.99      1.00      0.99       278\n",
      "         155       0.81      1.00      0.90        13\n",
      "         156       0.98      1.00      0.99        60\n",
      "         157       1.00      1.00      1.00       221\n",
      "         158       0.00      0.00      0.00         1\n",
      "         159       0.98      1.00      0.99       255\n",
      "         160       1.00      1.00      1.00        49\n",
      "         161       1.00      0.94      0.97        34\n",
      "         162       0.00      0.00      0.00         1\n",
      "         163       1.00      1.00      1.00       710\n",
      "         164       0.98      0.97      0.98        65\n",
      "         165       0.93      0.93      0.93        15\n",
      "         166       1.00      1.00      1.00         1\n",
      "         167       1.00      1.00      1.00       429\n",
      "         168       0.97      1.00      0.98        32\n",
      "         169       1.00      1.00      1.00      3204\n",
      "         170       0.98      0.99      0.98       165\n",
      "         171       1.00      1.00      1.00       275\n",
      "         172       0.99      0.99      0.99        88\n",
      "         173       1.00      1.00      1.00        25\n",
      "         174       1.00      1.00      1.00       157\n",
      "         175       0.98      1.00      0.99       101\n",
      "         176       1.00      0.88      0.93         8\n",
      "         177       0.94      0.98      0.96        46\n",
      "         178       1.00      1.00      1.00       111\n",
      "         179       0.92      0.96      0.94        85\n",
      "         180       1.00      1.00      1.00         2\n",
      "         181       1.00      1.00      1.00        28\n",
      "         182       0.99      0.99      0.99       149\n",
      "         184       1.00      0.99      0.99        67\n",
      "         185       1.00      1.00      1.00        23\n",
      "         186       1.00      0.67      0.80         3\n",
      "         187       1.00      0.95      0.97        40\n",
      "         188       0.81      0.92      0.86        24\n",
      "         189       1.00      1.00      1.00       340\n",
      "         190       1.00      1.00      1.00        47\n",
      "         191       0.94      0.96      0.95        49\n",
      "         192       0.99      1.00      0.99        76\n",
      "         193       1.00      0.99      1.00       409\n",
      "         194       1.00      1.00      1.00       246\n",
      "         195       1.00      1.00      1.00         5\n",
      "         196       0.99      1.00      1.00       474\n",
      "         197       1.00      0.97      0.99        36\n",
      "         198       0.73      0.73      0.73        11\n",
      "         199       1.00      1.00      1.00      1798\n",
      "         200       0.00      0.00      0.00         2\n",
      "         201       1.00      0.86      0.92        14\n",
      "         202       0.92      1.00      0.96        11\n",
      "         203       0.98      1.00      0.99       165\n",
      "         204       0.94      0.94      0.94        16\n",
      "         205       0.00      0.00      0.00         2\n",
      "         206       0.90      0.88      0.89        32\n",
      "         207       1.00      0.92      0.96        24\n",
      "         208       1.00      1.00      1.00       355\n",
      "         209       1.00      0.99      1.00       130\n",
      "         210       0.89      0.89      0.89         9\n",
      "         211       1.00      0.97      0.99        34\n",
      "         212       0.95      0.90      0.92        20\n",
      "         213       1.00      0.97      0.99        75\n",
      "         214       0.00      0.00      0.00         1\n",
      "         215       0.98      0.99      0.99       132\n",
      "         216       1.00      1.00      1.00      1370\n",
      "         217       1.00      0.81      0.90        16\n",
      "         218       1.00      1.00      1.00        26\n",
      "         219       1.00      0.98      0.99        56\n",
      "         220       0.99      0.99      0.99        82\n",
      "         221       1.00      1.00      1.00       302\n",
      "         222       1.00      1.00      1.00      2911\n",
      "         223       1.00      1.00      1.00       204\n",
      "         224       0.75      0.50      0.60         6\n",
      "         225       1.00      1.00      1.00       279\n",
      "         226       0.91      1.00      0.95        20\n",
      "         227       1.00      0.97      0.98        96\n",
      "         228       0.94      0.99      0.96        82\n",
      "         229       0.00      0.00      0.00         2\n",
      "         230       1.00      1.00      1.00        32\n",
      "         231       1.00      1.00      1.00         5\n",
      "         232       1.00      1.00      1.00       392\n",
      "         233       0.99      0.99      0.99       127\n",
      "         234       1.00      1.00      1.00       233\n",
      "         235       0.96      0.96      0.96       134\n",
      "         236       0.96      1.00      0.98       161\n",
      "         237       0.97      0.99      0.98        71\n",
      "         238       0.00      0.00      0.00         6\n",
      "         239       1.00      1.00      1.00       627\n",
      "         240       1.00      0.88      0.93         8\n",
      "         241       0.98      1.00      0.99        45\n",
      "         242       0.90      0.97      0.93        36\n",
      "         243       1.00      1.00      1.00        12\n",
      "         244       0.96      1.00      0.98       123\n",
      "         245       0.98      0.99      0.99       186\n",
      "         246       0.98      0.98      0.98       131\n",
      "         247       1.00      1.00      1.00       294\n",
      "         248       1.00      0.92      0.96        39\n",
      "         249       0.93      0.93      0.93        27\n",
      "         250       1.00      0.89      0.94         9\n",
      "         251       1.00      1.00      1.00       142\n",
      "         252       1.00      1.00      1.00       615\n",
      "         253       1.00      0.99      1.00       136\n",
      "         254       0.99      0.98      0.99       136\n",
      "         255       1.00      1.00      1.00         6\n",
      "         256       1.00      1.00      1.00        83\n",
      "         257       0.97      0.97      0.97        31\n",
      "         258       1.00      0.80      0.89        10\n",
      "         259       0.00      0.00      0.00         0\n",
      "         260       1.00      1.00      1.00        28\n",
      "         261       1.00      1.00      1.00       225\n",
      "         262       1.00      1.00      1.00       127\n",
      "         263       1.00      0.82      0.90        11\n",
      "         264       0.97      0.97      0.97        38\n",
      "         265       1.00      1.00      1.00         3\n",
      "         266       1.00      1.00      1.00         8\n",
      "\n",
      "    accuracy                           0.99     41239\n",
      "   macro avg       0.93      0.92      0.92     41239\n",
      "weighted avg       0.99      0.99      0.99     41239\n",
      "\n",
      "Accuracy: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\juan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\juan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\juan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\juan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\juan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "\n",
    "# Asumiendo que `y_test` son tus etiquetas verdaderas y `predictions` las predicciones del modelo\n",
    "print(classification_report(y_test_encoded, predicciones))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, predicciones))\n",
    "# Para AUC-ROC, asegúrate de que es un problema de clasificación binaria o calcula el AUC para cada clase individualmente en problemas multiclase\n",
    "# print(\"AUC-ROC:\", roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\juan\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:737: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define el modelo\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Define el espacio de búsqueda de hiperparámetros\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Configura la búsqueda\n",
    "search = GridSearchCV(model, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Ejecuta la búsqueda\n",
    "search.fit(X_train, y_train_encoded)\n",
    "\n",
    "# Mejores parámetros y puntuación\n",
    "print(\"Mejores parámetros:\", search.best_params_)\n",
    "print(\"Mejor puntuación:\", search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Evaluamos el rendimiento\n",
    "train_accuracy=accuracy_score(y_train_encoded, search.predict(X_train))\n",
    "test_accuracy=accuracy_score(y_test_encoded, search.predict(X_test))\n",
    "\n",
    "print('Train accuracy:', train_accuracy)\n",
    "print('Test accuracy:', test_accuracy)\n",
    "\n",
    "if train_accuracy > test_accuracy + 0.05:  # Umbral de 0.05 es arbitrario\n",
    "    print(\"Posible sobreajuste detectado.\")\n",
    "else:\n",
    "    print(\"No se detecta sobreajuste significativo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Guarda el mejor modelo\n",
    "mejor_modelo = search.best_estimator_\n",
    "dump(mejor_modelo, 'mejor_modelo.joblib')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
